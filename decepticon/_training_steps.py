# -*- coding: utf-8 -*-
import tensorflow as tf
import tensorflow.keras.backend as K

from decepticon._losses import least_squares_gan_loss, compute_style_loss
from decepticon._losses import total_variation_loss, compute_gradient_penalty

@tf.function
def maskgen_training_step(opt, inpt_img, maskgen, classifier, 
                          inpainter, maskdisc=None, cls_weight=1, exp_weight=0.1,
                          prior_weight=0.25, tv_weight=0, inpaint=True,
                          class_prob_loss=False):
    """
    TensorFlow function to perform one training step on the mask generator.
    
    NOT currently set up for multi-class training.
    
    :opt: keras optimizer
    :input_img: batch of input images
    :maskgen: mask generator model
    :classifier: classifier model
    :inpainter: inpainting model
    :maskdisc: mask discriminator model, if using one
    :cls_weight: weight for classification loss (in paper: 12)
    :exp_weight: weight for exponential loss (in paper: 18)
    :prior_weight: weight for mask discriminator loss (in paper: 3)
    :tv_weight: weight total variation loss (not in paper)
    :inpaint: if True, fill in the mask using the inpainter before computing
        classification loss (the way they did it in the paper)
    :class_prob_loss: use the probability rather than crossentropy for
        classification loss
    
    Returns
    :cls_loss: classification loss for the batch
    :exp_loss: exponential loss for the batch
    :prior_loss: loss from the mask discriminator for the batch
    :tv_loss: total variation loss from the batch
    :loss: total weighted loss for the batch
    :mask: batch masks (for use in mask buffer)
    """
    input_shape = inpt_img.get_shape()
    tv_norm = input_shape[1]*input_shape[2]
    
    with tf.GradientTape() as tape:
        # predict a mask from the original image and mask it
        mask = maskgen(inpt_img)
        inverse_mask = 1-mask
        masked_inpt = inpt_img*inverse_mask 
        
        if inpaint:
            # fill in with inpainter
            inpainted = inpainter(tf.concat([masked_inpt, mask], 3))
            y = masked_inpt + mask*inpainted
        else:
            y = masked_inpt
        # run masked image through classifier
        softmax_out = classifier(y)
            
    
        # compute losses
        if class_prob_loss:
            cls_loss = tf.reduce_mean(1-softmax_out[:,0])
        else:
            cls_loss = tf.reduce_mean(-1*tf.math.log(softmax_out[:,0] + K.epsilon()))
            
        exp_loss = tf.reduce_mean(
                            tf.exp(tf.reduce_mean(mask, axis=[1,2,3])))
        if (prior_weight > 0) & (maskdisc is not None):
            prior_loss = -1*tf.reduce_sum(maskdisc(mask))
        else:
            prior_loss = 0
            
        if tv_weight > 0:
            tv_loss = total_variation_loss(mask)/tv_norm
        else:
            tv_loss = 0
        loss = cls_weight*cls_loss + exp_weight*exp_loss + \
                    prior_weight*prior_loss + tv_weight*tv_loss
        
    # compute gradients and update
    variables = maskgen.trainable_variables
    gradients = tape.gradient(loss, variables)
    opt.apply_gradients(zip(gradients, variables))
    
    return cls_loss, exp_loss, prior_loss, tv_loss, loss, mask



@tf.function
def mask_discriminator_training_step(maskdisc, mask, prior_sample, opt, gradient_penalty=0):
    """
    TensorFlow function to perform one training step for the mask discriminator.
    
    :maskdisc: mask discriminator model
    :mask: batch of masks generated by mask generator
    :prior_sample: sample from prior distribution over masks
    :opt: keras optimizer
    :gradient_penalty: weight for wasserstein-GAN gradient penalty
    """
    with tf.GradientTape() as tape:
        # compute losses with respect to actual masks and samples
        # from the mask prior
        gen_loss = tf.reduce_mean(maskdisc(mask))
        prior_loss = tf.reduce_mean(maskdisc(prior_sample))
        
        if gradient_penalty > 0:
            gp = compute_gradient_penalty(mask, prior_sample, maskdisc)
        else:
            gp = 0
        
        wgan_loss = gen_loss - prior_loss + gradient_penalty*gp
                
    wgan_grads = tape.gradient(wgan_loss, maskdisc.trainable_variables)
    opt.apply_gradients(zip(wgan_grads, maskdisc.trainable_variables))
    return wgan_loss, gp
    



@tf.function
def inpainter_training_step(inpaint_opt, disc_opt, inpt_img, mask, inpainter,
                            disc, recon_weight=100,
                            disc_weight=2, style_weight=0, 
                            tv_weight=0, style_model=None,
                            gradient_penalty=0):
    """
    TensorFlow function to perform one training step on the inpainter as well
    as the inpainter's discriminator.
    
    NOT currently set up for multi-class training.
    
    :inpaint_opt: keras optimizer for inpainter
    :disc_opt: keras optimizer for discriminator
    :input_img: batch of input images
    :mask: batch of masks from mask buffer
    :inpainter: inpainting model
    :disc: discriminator model
    :recon_weight: reconstruction loss weight (equations 6, 9)
    :disc_weight: discriminator loss weight (equations 7, 9)
    :style_weight: weight for style loss (equations 6, 9)
    :tv_weight: weight for total variation loss (equation 9)
    :style_model: model to use for computing style representation
    
    Returns
    :recon_loss: reconstruction loss for the batch
    :disc_loss: inpainter loss from the discriminator 
    :style_loss: neural style loss for the batch
    :tv_loss: total variation loss for the batch
    :loss: total weighted loss for the batch
    :d_loss: discriminator loss
    """
    input_shape = inpt_img.get_shape()
    tv_norm = input_shape[1]*input_shape[2]*input_shape[3]
    
    with tf.GradientTape() as inp_tape, tf.GradientTape() as disc_tape:
        # predict a mask from the original image and mask it
        inverse_mask = 1 - mask
        masked_inpt = inpt_img*inverse_mask 
        
        # fill in with inpainter
        inpainted = inpainter(tf.concat([masked_inpt, mask], 3))
        y = masked_inpt + mask*inpainted
        
        # run masked image through discriminator
        # note that outputs will be (batch_size, X, Y, 1)
        sigmoid_out = disc(y)
    
        # ----- INPAINTER LOSSES --------
        # compute losses. style loss only computed if weight is nonzero
        recon_loss = tf.reduce_mean(tf.abs(y - inpt_img))
        # this is the discriminator's loss ON THE INPAINTER
        disc_loss = tf.reduce_mean(-1*tf.math.log(1 - sigmoid_out + K.epsilon()))
        
        if (style_weight > 0)&(style_model is not None):
            style_loss = compute_style_loss(inpt_img, y, style_model)
        else:
            style_loss = 0
        if tv_weight > 0:
            tv_loss = total_variation_loss(y)/tv_norm
        else:
            tv_loss = 0
        
        loss = recon_weight*recon_loss + disc_weight*disc_loss + \
                style_weight*style_loss + tv_weight*tv_loss
                
        # ----- DISCRIMINATOR LOSSES --------
        if gradient_penalty > 0:
            gp = compute_gradient_penalty(inpt_img, y, disc)
        else:
            gp = 0
        d_loss = tf.reduce_mean(least_squares_gan_loss(mask, sigmoid_out)) + \
                        gradient_penalty
        
    # compute gradients and update
    inp_variables = inpainter.trainable_variables
    inp_gradients = inp_tape.gradient(loss, inp_variables)
    inpaint_opt.apply_gradients(zip(inp_gradients, inp_variables))
    
    disc_variables = disc.trainable_variables
    disc_gradients = disc_tape.gradient(d_loss, disc_variables)
    disc_opt.apply_gradients(zip(disc_gradients, disc_variables))
    
    return recon_loss, disc_loss, style_loss, tv_loss, loss, d_loss, gp
